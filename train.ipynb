{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from IPython.display import clear_output\n",
    "from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "print('imported')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n",
      "Device name: NVIDIA RTX A6000\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "DATA_DIR = './data/'\n",
    "WEIGHT_DIR = './weights/'\n",
    "STATS_DIR = './stats/'\n",
    "\n",
    "# creating main paths\n",
    "if not os.path.exists(WEIGHT_DIR):\n",
    "    os.mkdir(WEIGHT_DIR)\n",
    "if not os.path.exists(STATS_DIR):\n",
    "    os.mkdir(STATS_DIR)\n",
    "\n",
    "# working device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Selected device: {}'.format(device))\n",
    "print('Device name: {}'.format(torch.cuda.get_device_name(device)))\n",
    "\n",
    "# other cosntants\n",
    "# you can modify from here: and only modify whats possible to modify (for backbones and optimizers)\n",
    "DATASET = 'mnist'\n",
    "assert DATASET in ['mnist', 'cifar10', 'brats'], 'Choose an available dataset'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "IMG_SIZE = (128, 128) if DATASET == 'brats' else (32, 32)\n",
    "LEARNING_RATE = 0.01\n",
    "LATENT_DIM = 4\n",
    "IN_CHANNELS = 1\n",
    "NUM_CHANNELS = 256\n",
    "BOTTLENECK_RATIO = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 900\n",
      "Number of test samples: 100\n",
      "Number of iterations per epoch: 900\n",
      "Image size: torch.Size([900, 1, 28, 28])\n",
      "Image max value: 1.0\n",
      "Image min value: 0.0\n"
     ]
    }
   ],
   "source": [
    "class IdentityDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, transform=None):\n",
    "        self.x = x\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.transform:\n",
    "            return self.transform(self.x[idx])\n",
    "        return self.x[idx]\n",
    "\n",
    "# dans un premier lieu, nous allons travailler avec MNIST\n",
    "mnist = torchvision.datasets.MNIST(root=DATA_DIR, train=True, download=True)\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "# removing some digits to reduce the size of the dataset\n",
    "selected_index = np.isin(mnist.targets, [1, 2, 3])\n",
    "images = mnist.data[selected_index][:n_samples]\n",
    "targets = mnist.targets[selected_index][:n_samples]\n",
    "\n",
    "# preprocessing\n",
    "images = images.div(255).type(torch.float32)\n",
    "images = images.unsqueeze(1)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(images, targets, test_size=0.1, random_state=42)\n",
    "\n",
    "print('Number of training samples: {}'.format(len(train_x)))\n",
    "print('Number of test samples: {}'.format(len(test_x)))\n",
    "print('Number of iterations per epoch: {}'.format(len(train_x // BATCH_SIZE)))\n",
    "print('Image size: {}'.format(train_x.shape))\n",
    "print('Image max value: {}'.format(train_x.max()))\n",
    "print('Image min value: {}'.format(train_x.min()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BraTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 900\n",
      "Number of test samples: 100\n",
      "Image size: torch.Size([32, 32])\n",
      "Total shape: torch.Size([900, 1, 32, 32])\n",
      "Max pixel value: 0.9964683055877686\n",
      "Min pixel value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# loading brats dataset\n",
    "data = np.load(os.path.join(DATA_DIR, 'brats_data.npz'))\n",
    "flair, t1 = data['flair'], data['t1']\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "n_max_flair = [flair[i].max() for i in range(flair.shape[0])]\n",
    "n_max_t1 = [t1[i].max() for i in range(t1.shape[0])]\n",
    "\n",
    "for idx in range(0, flair.shape[0]):\n",
    "    flair[idx] = (flair[idx] / n_max_flair[idx]).astype(np.float32)\n",
    "    t1[idx] = (t1[idx] / n_max_t1[idx]).astype(np.float32)\n",
    "\n",
    "flair = torch.tensor(flair, dtype=torch.float32).unsqueeze(1)\n",
    "t1 = torch.tensor(t1, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# resize images\n",
    "if IMG_SIZE != flair.shape[2:]:\n",
    "    flair = T.functional.resize(flair, IMG_SIZE)\n",
    "    t1 = T.functional.resize(t1, IMG_SIZE)\n",
    "\n",
    "# splitting dataset\n",
    "n_train = int(0.9 * flair.shape[0])\n",
    "flair_train_x, flair_test_x = flair[:n_train], flair[n_train:]\n",
    "t1_train_x, t1_test_x = t1[:n_train], t1[n_train:]\n",
    "\n",
    "# visualizing a sample\n",
    "n_to_visualize = 5\n",
    "rand_idx = np.random.randint(0, flair_train_x.shape[0], n_to_visualize)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(np.hstack([flair_train_x[idx, 0] for idx in rand_idx]), cmap='gray')\n",
    "plt.title('Flair')\n",
    "plt.axis('off')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(np.hstack([t1_train_x[idx, 0] for idx in rand_idx]), cmap='gray')\n",
    "plt.title('T1')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Number of training samples: {}'.format(flair_train_x.shape[0]))\n",
    "print('Number of test samples: {}'.format(flair_test_x.shape[0]))\n",
    "print('Image size: {}'.format(flair_train_x.shape[2:]))\n",
    "print('Total shape: {}'.format(flair_train_x.shape))\n",
    "print('Max pixel value: {}'.format(flair.max()))\n",
    "print('Min pixel value: {}'.format(flair.min()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm\n",
    "normalize = lambda x: x / 255.0\n",
    "denormalize = lambda x: x * 255.0\n",
    "\n",
    "def save_image(img, filename):\n",
    "    plt.figure(figsize=(25, 25))        \n",
    "    for i in range(100):\n",
    "        plt.subplot(10, 10, i + 1)\n",
    "        plt.imshow(img[i].squeeze(0).detach().cpu().numpy(), cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.savefig(os.path.join(STATS_DIR, filename), bbox_inches='tight', pad_inches=0)\n",
    "\n",
    "def sample_and_save(model, **kwargs):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        g = model.sample(100, **kwargs)\n",
    "        filename = 'samples_{}_{}_{}.png'.format(type(model).__name__, IMG_SIZE[0], LATENT_DIM)\n",
    "        save_image(g, filename)\n",
    "    print('Saved image to {}'.format(filename))\n",
    "\n",
    "class PolyScheduler(_LRScheduler):\n",
    "    def __init__(self, optimizer, base_lr, max_steps, warmup_steps, last_epoch=-1):\n",
    "        self.base_lr = base_lr\n",
    "        self.warmup_lr_init = 0.0001\n",
    "        self.max_steps: int = max_steps\n",
    "        self.warmup_steps: int = warmup_steps\n",
    "        self.power = 2\n",
    "        super(PolyScheduler, self).__init__(optimizer, -1, False)\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def get_warmup_lr(self):\n",
    "        alpha = float(self.last_epoch) / float(self.warmup_steps)\n",
    "        return [self.base_lr * alpha for _ in self.optimizer.param_groups]\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch == -1:\n",
    "            return [self.warmup_lr_init for _ in self.optimizer.param_groups]\n",
    "        if self.last_epoch < self.warmup_steps:\n",
    "            return self.get_warmup_lr()\n",
    "        else:\n",
    "            alpha = pow(\n",
    "                1\n",
    "                - float(self.last_epoch - self.warmup_steps)\n",
    "                / float(self.max_steps - self.warmup_steps),\n",
    "                self.power,\n",
    "            )\n",
    "            return [self.base_lr * alpha for _ in self.optimizer.param_groups]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training en evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(\n",
    "        model, optimizer, epochs, dataloader, save_freq=EPOCHS // 10, resume=False, verbose=True, \n",
    "        sample_freq=EPOCHS // 10, weights_path=WEIGHT_DIR, stats_path=STATS_DIR, **kwargs\n",
    "    ): \n",
    "    model_name = type(model).__name__\n",
    "    optimizer_name = type(optimizer).__name__\n",
    "    checkpoint_filename = 'checkpoint_{}_{}_{}.pth'.format(model_name, IMG_SIZE[0], LATENT_DIM)\n",
    "\n",
    "    # In case the last learning was interrupted or manually stopped\n",
    "    if verbose: print('Resuming: {}'.format(resume))\n",
    "    if resume:\n",
    "        if os.path.exists(checkpoint_filename):\n",
    "            checkpoint = torch.load(checkpoint_filename)\n",
    "            if verbose: print('Model to resume: {} - Latent dim: {} - Image size: {}'.format(\n",
    "                checkpoint['backbone'], checkpoint['latent_dim'], checkpoint['img_size']\n",
    "            ))\n",
    "        else:\n",
    "            print('There is no corresponding checkpoint file for the given configuration.. Turn resume=False to start a new training')\n",
    "            return\n",
    "\n",
    "    if verbose:\n",
    "        print('Selected model: {}'.format(model_name))\n",
    "\n",
    "    # Loss function is a cross entropy. The most used function for multiclass classification\n",
    "    criterion = model.loss_function\n",
    "\n",
    "    # 1 single warm up step\n",
    "    warmup_step = len(dataloader) * 1 \n",
    "    total_step = len(dataloader) * epochs\n",
    "\n",
    "    lr_scheduler = PolyScheduler(\n",
    "        optimizer=optimizer,\n",
    "        base_lr=0.001,\n",
    "        max_steps=total_step,\n",
    "        warmup_steps=warmup_step,\n",
    "        last_epoch=-1\n",
    "    ) \n",
    "\n",
    "    if resume:\n",
    "        train_loss_history = checkpoint['train_loss_history'] # (total_loss, recon_loss, kld_loss)\n",
    "        start_epoch = checkpoint['epochs']\n",
    "        model.load_state_dict(checkpoint['model_state'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "        lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state'])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        train_loss_history = list()\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "\n",
    "        running_total_loss = 0.0\n",
    "        running_recon_loss = 0.0\n",
    "        running_kld_loss = 0.0\n",
    "\n",
    "        progress = None\n",
    "        if verbose: progress = tqdm(dataloader, position=0, leave=True)\n",
    "        for i, x in enumerate(dataloader):\n",
    "            x = x.to(device, dtype=torch.float32)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(True):\n",
    "                output = model(x)\n",
    "                stats = criterion(output['x'], x, output['mu'], output['logvar'])\n",
    "                # if training only\n",
    "                stats['loss'].backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            running_total_loss += stats['loss'].item()\n",
    "            running_recon_loss += stats['recon_loss'].item()\n",
    "            running_kld_loss += stats['kld_loss'].item()\n",
    "\n",
    "            if verbose:\n",
    "                with torch.no_grad():\n",
    "                    progress.update(1)\n",
    "                    progress.set_description('Epoch: {:5}/{} - Loss: {:.4f} - Recon Loss: {:.4f} - KL Loss: {:.4f}'.format(\n",
    "                        epoch + 1, EPOCHS, running_total_loss / (i + 1), running_recon_loss / (i + 1), running_kld_loss / (i + 1)\n",
    "                    ))\n",
    "\n",
    "        train_loss_history.append((\n",
    "            running_total_loss / dataloader.__len__(),\n",
    "            running_recon_loss / dataloader.__len__(),\n",
    "            running_kld_loss / dataloader.__len__()\n",
    "        ))\n",
    "\n",
    "        if (epoch + 1) % sample_freq == 0 and verbose:\n",
    "            # cleaning output\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # plotting generation\n",
    "            model.eval()\n",
    "            n_sample = 5\n",
    "            if kwargs.get('dt') is not None:\n",
    "                sample = model.sample(n_sample, dt=kwargs.get('dt'))\n",
    "            else:\n",
    "                sample = model.sample(n_sample)\n",
    "            sample = denormalize(sample).type(torch.uint8)\n",
    "            plt.figure(figsize=(10, 2))\n",
    "            for i in range(n_sample):\n",
    "                plt.subplot(1, n_sample, i + 1)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(sample[i].squeeze(0).detach().cpu(), cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "            # plotting reconstruction\n",
    "            x = torch.hstack([img for img in x[:n_sample].view(n_sample, 32, 32)])\n",
    "            x = denormalize(x).type(torch.uint8)\n",
    "            x_hat = torch.hstack([img for img in output['x'][:n_sample].view(n_sample, 32, 32)])\n",
    "            x_hat = denormalize(x_hat).type(torch.uint8)\n",
    "            plt.figure(figsize=(20, 4))\n",
    "            plt.subplot(2, 1, 1)\n",
    "            plt.axis('off')\n",
    "            plt.title('Original')\n",
    "            plt.imshow(torchvision.utils.make_grid(x, nrow=n_sample).detach().cpu().permute(1, 2, 0), cmap='gray')\n",
    "            plt.subplot(2, 1, 2)\n",
    "            plt.axis('off')\n",
    "            plt.title('Reconstruction')\n",
    "            plt.imshow(torchvision.utils.make_grid(x_hat, nrow=n_sample).detach().cpu().permute(1, 2, 0), cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "        if (epoch + 1) % save_freq == 0: \n",
    "            # checkpointing\n",
    "            # each epoch, states are saved\n",
    "            checkpoint = {\n",
    "                'model_state': model.state_dict(),\n",
    "                'optimizer_state': optimizer.state_dict(),\n",
    "                'lr_scheduler_state': lr_scheduler.state_dict(),\n",
    "                'train_loss_history': train_loss_history,\n",
    "                'epochs': epoch,\n",
    "                'latent_dim': LATENT_DIM,\n",
    "                'img_size': IMG_SIZE\n",
    "            }\n",
    "            torch.save(checkpoint, checkpoint_filename)\n",
    "            if verbose: print('saved checkpoint')\n",
    "\n",
    "        if verbose: progress.close()\n",
    "        del progress\n",
    "\n",
    "    # at this point training is over so we can delete the checkpoint and save only what we need\n",
    "    # remove the checkpoint file if it exists\n",
    "    if os.path.exists(checkpoint_filename):\n",
    "        os.remove(checkpoint_filename)\n",
    "\n",
    "    # saving stats\n",
    "    if STATS_DIR != None:\n",
    "        with open(os.path.join(STATS_DIR, 'stats_{}_{}_{}.pth'.format(model_name, IMG_SIZE[0], LATENT_DIM)), 'wb') as stats_file:\n",
    "            import pickle\n",
    "            pickle.dump(train_loss_history, stats_file)\n",
    "\n",
    "        if verbose: print('saved stats and weigts')\n",
    "\n",
    "    # freeing memory (those are the most memory consuming i guess)\n",
    "    del checkpoint\n",
    "\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return model, train_loss_history\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, verbose=True, **kwargs): \n",
    "    if verbose:\n",
    "        print('--------------------------------------------')\n",
    "        print('Test metrics (on test set)')\n",
    "\n",
    "    model_name = type(model).__name__\n",
    "    model.eval()\n",
    "\n",
    "    # computing predictions\n",
    "    for i, x in enumerate(tqdm(test_loader, position=0, leave=True)):\n",
    "        x = x.to(device, dtype=torch.float32)\n",
    "        output = model(x)\n",
    "        stats = model.loss_function(output['x'], x, output['mu'], output['logvar'])\n",
    "\n",
    "    # computing main metrics (loss, ssim, psnr)\n",
    "    elbo = stats['loss'].item()\n",
    "    recon_loss = stats['recon_loss'].item()\n",
    "    kld_loss = stats['kld_loss'].item()\n",
    "\n",
    "    # computing ssim and psnr from outputs\n",
    "    psnr = PeakSignalNoiseRatio().to(device)\n",
    "    psnr_score = psnr(output['x'], x)\n",
    "    ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    ssim_score = ssim(output['x'], x)\n",
    "    \n",
    "    real = torch.vstack([img for img in test_loader])\n",
    "    real = denormalize(real).type(torch.uint8).to(device)\n",
    "    fake = model.sample(len(test_loader), **kwargs)\n",
    "    fake = denormalize(fake).type(torch.uint8)\n",
    "    if real.shape[1] == 1:\n",
    "        real = real.repeat(1, 3, 1, 1)\n",
    "        fake = fake.repeat(1, 3, 1, 1)\n",
    "    fid = FrechetInceptionDistance(feature=64).to(device)\n",
    "    fid.update(real, real=True)\n",
    "    fid.update(fake, real=False)\n",
    "    fid_score = fid.compute()\n",
    "\n",
    "\n",
    "    # adding scores to the history\n",
    "    stats['psnr'] = psnr_score\n",
    "    stats['ssim'] = ssim_score\n",
    "\n",
    "    log = \"\"\"\n",
    "    --------------------------------------------\n",
    "    Total loss (ELBO): {:.3f}\n",
    "    Mean squared error: {:.3f}\n",
    "    Kullback-Leibler divergence: {:.3f}\n",
    "    PSNR: {:.3f}\n",
    "    SSIM: {:.3f}\n",
    "    FID: {:.3f}\n",
    "    kwargs: {}\n",
    "    --------------------------------------------\n",
    "    \"\"\".format(elbo, recon_loss, kld_loss, psnr_score, ssim_score, fid_score, kwargs)\n",
    "\n",
    "    with open(os.path.join(STATS_DIR, 'results_{}_{}_{}.txt'.format(model_name, IMG_SIZE[0], LATENT_DIM)), 'w') as txt_file:\n",
    "        txt_file.write(log)\n",
    "\n",
    "    if verbose: print(log)\n",
    "\n",
    "    return stats\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:    30/100 - Loss: 24.6054 - Recon Loss: 15.0061 - KL Loss: 9.5993: 100%|| 28/28 [00:03<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:    31/100 - Loss: 24.6221 - Recon Loss: 14.7908 - KL Loss: 9.8314: 100%|| 28/28 [00:02<00:00, 10.57it/s] \n",
      "Epoch:    32/100 - Loss: 24.1600 - Recon Loss: 14.4334 - KL Loss: 9.7266: 100%|| 28/28 [00:02<00:00, 11.13it/s]\n",
      "Epoch:    33/100 - Loss: 24.2637 - Recon Loss: 14.4354 - KL Loss: 9.8283: 100%|| 28/28 [00:02<00:00, 10.95it/s] \n",
      "Epoch:    34/100 - Loss: 24.3197 - Recon Loss: 14.4954 - KL Loss: 9.8242: 100%|| 28/28 [00:02<00:00, 11.05it/s]\n",
      "Epoch:    35/100 - Loss: 23.1831 - Recon Loss: 13.4900 - KL Loss: 9.6931: 100%|| 28/28 [00:02<00:00, 11.05it/s]\n",
      "Epoch:    36/100 - Loss: 23.4773 - Recon Loss: 13.5830 - KL Loss: 9.8943: 100%|| 28/28 [00:02<00:00, 11.22it/s]\n",
      "Epoch:    37/100 - Loss: 23.1338 - Recon Loss: 13.2569 - KL Loss: 9.8769: 100%|| 28/28 [00:02<00:00, 11.16it/s]\n",
      "Epoch:    38/100 - Loss: 23.2385 - Recon Loss: 13.4710 - KL Loss: 9.7675: 100%|| 28/28 [00:02<00:00, 11.32it/s]\n",
      "Epoch:    39/100 - Loss: 22.8579 - Recon Loss: 13.3502 - KL Loss: 9.5077:  14%|        | 4/28 [00:00<00:04,  5.72it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-140e2a6a6d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'dt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0msample_and_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-15ac3af3acaf>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, optimizer, epochs, dataloader, save_freq, resume, verbose, sample_freq, weights_path, stats_path, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mu'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logvar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;31m# if training only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/riemannian_variational_autoencoder/models/dvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparametrize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/riemannian_variational_autoencoder/models/dvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deeplearning/riemannian_variational_autoencoder/models/dvae.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_a\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_b\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from models.rvae import RVAE\n",
    "from models.vae import VAE\n",
    "from models.dvae import DVAE\n",
    "\n",
    "def parse_blocks_str(s):\n",
    "    blocks = []\n",
    "    for block in s.split(','):\n",
    "        if 'x' in block:\n",
    "            res, num = block.split('x')\n",
    "            blocks.extend([(int(res), None) for _ in range(int(num))])\n",
    "        elif 'd' in block:\n",
    "            res, down_rate = block.split('d')\n",
    "            blocks.append((int(res), int(down_rate)))\n",
    "        elif 'u' in block:\n",
    "            res, up_rate = block.split('u')\n",
    "            blocks.append((int(res), int(up_rate)))\n",
    "    return blocks\n",
    "\n",
    "enc_blocks = \"32x2,32d2,16x2,16d2,8x2,8d2,4x1\"\n",
    "dec_blocks = \"4x1,4u2,8x2,8u2,16x2,16u2,32x2\"\n",
    "ENC_BLOCKS = parse_blocks_str(enc_blocks)\n",
    "DEC_BLOCKS = parse_blocks_str(dec_blocks)\n",
    "\n",
    "\n",
    "# model = VAE(IN_CHANNELS, IN_CHANNELS, NUM_CHANNELS, LATENT_DIM, ENC_BLOCKS, DEC_BLOCKS, BOTTLENECK_RATIO).to(device)\n",
    "model = DVAE(IN_CHANNELS, IN_CHANNELS, LATENT_DIM, NUM_CHANNELS, enc_blocks, dec_blocks, BOTTLENECK_RATIO, riemannian=False, dt=0.1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(IdentityDataset(train_x, transform=T.Resize([32, 32])), batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(IdentityDataset(test_x, transform=T.Resize([32, 32])), batch_size=1, shuffle=False)\n",
    "\n",
    "kwargs = {'dt': 0.1}\n",
    "\n",
    "model, train_loss_history = train_loop(model, optimizer, EPOCHS, train_loader, **kwargs)\n",
    "_ = evaluate_model(model, test_loader, **kwargs)\n",
    "sample_and_save(model, dt=1.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Test metrics (on test set)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 100/100 [00:01<00:00, 67.59it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4f91479f0087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-15ac3af3acaf>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mfake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrechetInceptionDistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mfid_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m                             \u001b[0;34m\" device corresponds to the device of the input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                         ) from err\n\u001b[0;32m--> 399\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_on_cpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                     \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Expected all tensors to be on\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torchmetrics/image/fid.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, imgs, real)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;34m\"\"\"Update the state with extracted features.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torchmetrics/image/fid.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch_fidelity/feature_extractor_inceptionv3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# N x 3 x 299 x 299\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_1a_3x3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0;31m# N x 32 x 149 x 149\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d_2a_3x3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch_fidelity/feature_extractor_inceptionv3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/work/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "_ = evaluate_model(model, test_loader, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fae847446f25d1d5cccaa632528b81cb53ce4d6408a7df79225531d1adf33a86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
